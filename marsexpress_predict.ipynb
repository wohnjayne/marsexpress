{
 "metadata": {
  "name": "",
  "signature": "sha256:ad5a449bb6b555c21828bec15ed23493fb849e426276a8420419850c354c0f93"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from datetime import datetime\n",
      "import matplotlib.pyplot as plt\n",
      "from utils import *\n",
      "import time\n",
      "import os.path\n",
      "import gc\n",
      "#import matplotlib\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# some configs \n",
      "interval = 5 #minutes\n",
      "last_year_is_validation_set = False\n",
      "autoregressive_depth = 1\n",
      "timestamp_is_feature = False #  !!!!! the way means are handled for targets does not yet work if this is True\n",
      "first_timestamp = 1219363213000 # first time stamp from context file in training set\n",
      "last_timestamp  = 1456704000000 # last time stamp from context file in test set\n",
      "\n",
      "path = {}\n",
      "path[\"train\"] = \"/home/malte/data/mars-express-power-3years/train_set/\"\n",
      "path[\"validation\"] = path[\"train\"]\n",
      "path[\"test\"] = \"/home/malte/data/mars-express-power-3years/test_set/\"\n",
      "years = {}\n",
      "years[\"train\"] = [\"2008-08-22_2010-07-10\",\"2010-07-10_2012-05-27\",\"2012-05-27_2014-04-14\"]\n",
      "#years[\"train\"] = [\"2008-08-22_2010-07-10\",\"2010-07-10_2012-05-27\"]\n",
      "years[\"test\"] = [\"2014-04-14_2016-03-01\"]\n",
      "\n",
      "#apply_linear_trend = []\n",
      "apply_linear_trend = ['NPWD2372', 'NPWD2451', 'NPWD2491', 'NPWD2532', 'NPWD2561', 'NPWD2721', 'NPWD2791', 'NPWD2802', 'NPWD2851']\n",
      "bigInterval = 60*24\n",
      "\n",
      "if last_year_is_validation_set:\n",
      "    years['validation'] = [years['train'].pop(-1)]\n",
      "    years.pop('test')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'test': '/home/malte/data/mars-express-power-3years/test_set/', 'train': '/home/malte/data/mars-express-power-3years/train_set/', 'validation': '/home/malte/data/mars-express-power-3years/train_set/'}\n"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_saaf = {}\n",
      "data_ltdata = {}\n",
      "data_ftl = {}\n",
      "data = {}\n",
      "targets = {}\n",
      "train_targets_mean = 0\n",
      "train_targets_std = 1\n",
      "for data_type in years.keys():\n",
      "    print \"=== loading %s data ===\"%data_type  \n",
      "    # load and prepare saaf data\n",
      "    data_saaf[data_type] = load_or_pickle(path,years,data_type,'saaf',interval,keep_times=timestamp_is_feature)\n",
      "    \n",
      "    # load and prepare long term data\n",
      "    data_ltdata[data_type] = load_or_pickle(path,years,data_type,'ltdata',interval)\n",
      "    \n",
      "    # load and prepare ftl\n",
      "    data_ftl[data_type] = load_or_pickle(path,years, data_type,'ftl',interval,ftl=True)\n",
      "    \n",
      "    # concatenate data\n",
      "    # real-valued  data: interpolate NaNs\n",
      "    data[data_type] = pd.concat([data_saaf[data_type],data_ltdata[data_type]],axis=1).fillna(method='pad')\n",
      "    # flags: set nans to 0\n",
      "    data[data_type] = pd.concat([data[data_type],data_ftl[data_type]],axis=1).fillna(0)\n",
      "    \n",
      "    filenames_targets = [\"%spower--%s.csv\"%(path[data_type],year) for year in years[data_type]]\n",
      "    if data_type != 'test':\n",
      "        print \"-- targets --\"\n",
      "        targets[data_type] = load_data(filenames_targets)\n",
      "        \n",
      "        # normalize targets only for training set, and if we dont use the timestamp as input\n",
      "        if data_type == 'train' and not(timestamp_is_feature):\n",
      "            do_normalization = True\n",
      "        else:\n",
      "            do_normalization = False\n",
      "        \n",
      "        # remember std and mean of targets in training set\n",
      "        if do_normalization:\n",
      "            # omit mean/std for index\n",
      "            train_targets_mean = targets[data_type].mean().ix[1:]\n",
      "            train_targets_std = targets[data_type].std().ix[1:]\n",
      "        \n",
      "        \n",
      "        targets[data_type] = prepare_data(targets[data_type],interval,normalize = do_normalization)\n",
      "data_is_clean = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "=== loading test data ===\n",
        "-- saaf --\n",
        "loading preprocessed pickle file\n",
        "-- ltdata --"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "loading preprocessed pickle file\n",
        "-- ftl --"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "loading preprocessed pickle file\n",
        "=== loading train data ==="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "-- saaf --\n",
        "loading preprocessed pickle file\n",
        "-- ltdata --"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "loading preprocessed pickle file\n",
        "-- ftl --"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "loading preprocessed pickle file\n",
        "-- targets --"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading file /home/malte/data/mars-express-power-3years/train_set/power--2008-08-22_2010-07-10.csv\n",
        "reading file /home/malte/data/mars-express-power-3years/train_set/power--2010-07-10_2012-05-27.csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "reading file /home/malte/data/mars-express-power-3years/train_set/power--2012-05-27_2014-04-14.csv"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tpreparing data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "linear_coefficients={}\n",
      "if len(apply_linear_trend)>0:\n",
      "    for field in apply_linear_trend:\n",
      "        x = np.arange(len(targets['train']))\n",
      "        d = targets['train'][field]\n",
      "        #plt.plot(x,d)\n",
      "        m,b=np.polyfit(x,d,1)\n",
      "        linear_coefficients[field] = [m,b]\n",
      "        #plt.plot(x,x*m+b,'-')\n",
      "        #print \"m=%f\"%(m)\n",
      "        #plt.title(field)\n",
      "            \n",
      "        #plt.show()\n",
      "for field in linear_coefficients.keys():\n",
      "    m,offset = linear_coefficients[field]\n",
      "    trend = pd.DataFrame((np.arange(len(targets['train']))*m)+offset,index=targets['train'].index, columns=[field])\n",
      "    #targets['train'][field] =\n",
      "    targets['train'][field] = targets['train'][field] - trend[field]\n",
      "data_clean = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print linear_coefficients"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'NPWD2802': [2.0964487514211841e-07, -0.064840829941652925], 'NPWD2791': [-4.6349490882405664e-07, 0.138090112244701], 'NPWD2372': [5.4012874380577524e-07, -0.15901723542592569], 'NPWD2721': [5.2311715967469987e-07, -0.15821482439140369], 'NPWD2561': [-6.9772194299576217e-08, 0.020040134226818017], 'NPWD2851': [1.688006355041612e-06, -0.50191895919913276], 'NPWD2532': [5.4911649267844339e-07, -0.16374305142429393], 'NPWD2451': [5.4870719042400825e-07, -0.16239217102394918], 'NPWD2491': [2.5836336741302431e-07, -0.077454223861954635]}\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for data_type in years.keys():\n",
      "    if not data_type == 'test':\n",
      "        data[data_type],targets[data_type] = match_length(data[data_type],targets[data_type])\n",
      "\n",
      "if autoregressive_depth > 1 and data_is_clean:\n",
      "    data = augment_data_for_autoregression(data,autoregressive_depth)\n",
      "    data_is_clean = False\n",
      "\n",
      "if  last_year_is_validation_set:\n",
      "    input_for_prediction = data['validation']\n",
      "else:\n",
      "    input_for_prediction = data['test']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "need to cut 4 points from data\n",
        "need to cut 0 points from data\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import linear_model\n",
      "lr = linear_model.LinearRegression()\n",
      "lr.fit(data['train'].as_matrix(),targets['train'].as_matrix())\n",
      "predictions = pd.DataFrame(lr.predict(input_for_prediction.as_matrix()),columns=targets['train'].columns,index=input_for_prediction.index)\n",
      "\n",
      "for field in linear_coefficients.keys():\n",
      "    m,offset = linear_coefficients[field]\n",
      "    trend = pd.DataFrame((np.arange(len(targets['train']),len(targets['train'])+len(predictions))*m)+offset,index=predictions.index, columns=[field])\n",
      "    predictions[field] =  predictions[field] + trend[field]\n",
      "# resample predictions to intervals of 60 minutes\n",
      "predictions = predictions.resample(\"60T\").mean()*train_targets_std + train_targets_mean\n",
      "\n",
      "\n",
      "\n",
      "model_type = \"LinearRegression\"\n",
      "if  last_year_is_validation_set:\n",
      "    err = evaluate_predictions(predictions,targets['validation'].resample(\"60T\").mean())\n",
      "    print \"Error of\",model_type, err\n",
      "else:\n",
      "    save_predictions(predictions,model_type)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "saved predictions to /tmp/predictionsLinearRegression.csv\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### plot residuals\n",
      "\n",
      "for field in predictions.columns:\n",
      "    bigInterval = 60*24*10\n",
      "    #field = 'NPWD2372'\n",
      "    d = predictions[field].resample(\"%dT\"%bigInterval).mean()\n",
      "    t = targets['validation'][field].resample(\"%dT\"%bigInterval).mean()\n",
      "    if d.mean() > 0.1 and d.std()> 1e-3:\n",
      "        x = np.arange(len(d))\n",
      "        plt.plot(x,d)\n",
      "        plt.plot(x,t)\n",
      "        #m,b=np.polyfit(x,d,1)\n",
      "        #plt.plot(x,x*m+b,'-')\n",
      "        #print \"m=%f\"%(m)\n",
      "        plt.legend(['Predictions','Targets'])\n",
      "        plt.title(field)\n",
      "        plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'validation'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-69-9efecd906273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#field = 'NPWD2372'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%dT\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbigInterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%dT\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mbigInterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: 'validation'"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import tree\n",
      "# initial tests on validation set (year 3) show that min_samples_leaf should\n",
      "# be pretty high (280) when predicting 10 minute intervals, m\n",
      "# min_samples_split is less sensitive, 60 is ok\n",
      "def decisionTreeRegressor(min_samples_leaf=280,min_samples_split=60):\n",
      "    clf = tree.DecisionTreeRegressor(min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split)\n",
      "    first = True\n",
      "    for col in targets['train'].columns:\n",
      "        #print col,\n",
      "        clf.fit(data['train'].as_matrix(),targets['train'][[col]].as_matrix())\n",
      "        pred = pd.DataFrame(clf.predict(input_for_prediction.as_matrix()),columns=[col],index=input_for_prediction.index)\n",
      "        if first:\n",
      "            predictions = pred\n",
      "            first = False\n",
      "        else:\n",
      "            predictions = pd.concat([predictions,pred],axis=1)    \n",
      "    # resample predictions to intervals of 60 minutes\n",
      "    predictions = predictions.resample(\"60T\").mean()*train_targets_std + train_targets_mean\n",
      "    return predictions\n",
      "    #if  last_year_is_validation_set:\n",
      "    #    return marsexpress_error(predictions.as_matrix(),targets['validation'].resample(\"60T\").mean().as_matrix())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = decisionTreeRegressor()\n",
      "model_type = \"RegressionTree\"\n",
      "if  last_year_is_validation_set:\n",
      "    print \"Error of\",model_type, elvaluate_predictions(predictions)\n",
      "else:\n",
      "    save_predictions(predictions,model_type)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### Paramter testing for decision tree\n",
      "results=[]\n",
      "from IPython.display import clear_output\n",
      "for i in range(0):\n",
      "    print i,\n",
      "    min_samples_leaf = np.random.randint(500,1000)\n",
      "    min_samples_split = np.random.randint(1,500)\n",
      "    results.append([min_samples_leaf,min_samples_split,decisionTreeRegressor(min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split)])\n",
      "    print \" -> \",results[-1]\n",
      "    clear_output()\n",
      "    results2 = np.array(results)\n",
      "    plt.scatter(results2[:,0],results2[:,2])\n",
      "    plt.title('min_samples_leaf')\n",
      "    plt.show()\n",
      "    plt.scatter(results2[:,1],results2[:,2])\n",
      "    plt.title('min_samples_split')\n",
      "    plt.show()\n",
      "print \"\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}